{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T04:20:59.032209Z",
     "start_time": "2018-07-18T04:20:55.446828Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "import warnings\n",
    "import time \n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T04:21:04.248934Z",
     "start_time": "2018-07-18T04:20:59.034172Z"
    }
   },
   "outputs": [],
   "source": [
    "file = \"big_df_v2.csv\"  #large file for production\n",
    "#file = \"small_R_df.csv\"       #small file for development\n",
    "df = pd.read_csv('private/'+file, delimiter='|', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T04:21:09.265689Z",
     "start_time": "2018-07-18T04:21:04.251892Z"
    }
   },
   "outputs": [],
   "source": [
    "#### stripping HTML tags ####\n",
    "p = '<.*?>'\n",
    "for col in df.columns:\n",
    "    df[col] = df[col].replace(p, '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T04:21:10.780621Z",
     "start_time": "2018-07-18T04:21:09.268477Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model           247144\n",
       "parentItemId      3974\n",
       "itemId            3515\n",
       "shortDn            204\n",
       "main_cat             0\n",
       "sub_cat              0\n",
       "catNode              0\n",
       "longDn               0\n",
       "categoryPath         0\n",
       "name                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# splitting categories into main and sub, dropping non-Book main categories #\n",
    "regex = r\"\\/(.*?)\\/.*\"\n",
    "\n",
    "df['sub_cat'] = df['categoryPath'].str.extract(regex) # sub categories, one level below Books.\n",
    "df['main_cat'] = df['categoryPath'].astype(str).str[:5] \n",
    "df = df[df.main_cat == 'Books'] #dropping non-Book categories\n",
    "\n",
    "# drop rows missing critical data #\n",
    "df = df.dropna(axis=0, how='any', subset=['longDn', 'sub_cat','name'])\n",
    "df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T04:21:10.907247Z",
     "start_time": "2018-07-18T04:21:10.783051Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 74 categories of books.\n",
      "56 categories have more than 100 books.\n"
     ]
    }
   ],
   "source": [
    "print(\"There are \" + str(len(df.sub_cat.value_counts())) + \" categories of books.\")\n",
    "counts = df['sub_cat'].value_counts()\n",
    "threshold = 100\n",
    "print(str(len(counts[counts>threshold])) + \" categories have more than \" + str(threshold) +\" books.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T04:21:11.013810Z",
     "start_time": "2018-07-18T04:21:10.909093Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Business & Money Books                      20783\n",
      "Children's & Kids' Books                    19813\n",
      "Medical Books                               19255\n",
      "History Books                               16745\n",
      "Education Books                             14129\n",
      "Computers & Technology Books                12787\n",
      "Law Books                                   11642\n",
      "Biographies & Memoirs                       10261\n",
      "Sports & Outdoor Books                      10054\n",
      "Political Books                              9292\n",
      "Language Arts & Disciplines Books            7501\n",
      "Self-Help Books                              7103\n",
      "Health & Wellness Books                      6852\n",
      "Crafts & Hobbies Books                       6475\n",
      "Mathematics Books                            6388\n",
      "Philosophy Books                             6114\n",
      "Travel Books                                 5810\n",
      "Reference Books                              5681\n",
      "Foreign Language Study & Reference Books     5561\n",
      "Teen & Young Adult Books                     5358\n",
      "Cookbooks, Food & Wine                       5031\n",
      "Comic Books & Graphic Novels                 4710\n",
      "Study Aids & Test Prep Books                 3848\n",
      "Humor Books                                  3492\n",
      "Literature & Fiction Books                   3203\n",
      "Arts & Entertainment Books                   2588\n",
      "Religion & Spirituality Books                2518\n",
      "Psychology & Social Science Books            2371\n",
      "Science & Nature Books                       1940\n",
      "Libros en Espanol                            1618\n",
      "Engineering & Transportation Books           1472\n",
      "True Crime Books                             1394\n",
      "House, Home & Gardening Books                1368\n",
      "Dieting & Fitness Books                      1360\n",
      "Law                                          1151\n",
      "Nonfiction                                   1000\n",
      "Business & Money                              983\n",
      "Language Arts & Disciplines                   582\n",
      "History                                       529\n",
      "Name: sub_cat, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "Top_40_cats = df.sub_cat.value_counts().iloc[:39].index.tolist()\n",
    "\n",
    "# Print number of titles represented in each of the Top 40 categories #\n",
    "print(df.sub_cat.value_counts().iloc[:39])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T04:21:11.081729Z",
     "start_time": "2018-07-18T04:21:11.015839Z"
    }
   },
   "outputs": [],
   "source": [
    "# Only keep records for top n populated categories (drop sparsely populated categories) #\n",
    "df = df.loc[df['sub_cat'].isin(Top_40_cats)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Corpus and BOW for LDA Topic Modeling with Gensim\n",
    "#### references used:\n",
    "> http://mallet.cs.umass.edu/  \n",
    "> https://radimrehurek.com/gensim/models/ldamodel.html  \n",
    "> https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/  \n",
    "> https://radimrehurek.com/gensim/models/wrappers/ldamallet.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T04:21:20.556108Z",
     "start_time": "2018-07-18T04:21:11.083622Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "\n",
    "import nltk#; nltk.download('stopwords')\n",
    "#!python3 -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T04:21:24.804945Z",
     "start_time": "2018-07-18T04:21:20.559678Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import spacy\n",
    "\n",
    "# Fancy LDA visualization tool\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Enable gensim logging \n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T04:21:24.829088Z",
     "start_time": "2018-07-18T04:21:24.809969Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['book'])\n",
    "#stop_words.extend(['book', 'new']) # decided extra stop words could be introducing bias "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T04:21:24.905814Z",
     "start_time": "2018-07-18T04:21:24.834862Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Arts & Entertainment Books' \"Children's & Kids' Books\"\n",
      " 'Business & Money Books' 'Cookbooks, Food & Wine'\n",
      " 'Crafts & Hobbies Books' 'Literature & Fiction Books'\n",
      " 'Religion & Spirituality Books' 'Dieting & Fitness Books'\n",
      " 'Study Aids & Test Prep Books' 'Health & Wellness Books'\n",
      " 'Biographies & Memoirs' 'Reference Books' 'Humor Books'\n",
      " 'Libros en Espanol' 'Computers & Technology Books'\n",
      " 'Comic Books & Graphic Novels' 'Teen & Young Adult Books' 'Medical Books'\n",
      " 'Self-Help Books' 'History Books' 'True Crime Books'\n",
      " 'Psychology & Social Science Books' 'House, Home & Gardening Books'\n",
      " 'Travel Books' 'Education Books' 'Engineering & Transportation Books'\n",
      " 'Science & Nature Books' 'Language Arts & Disciplines Books' 'Law Books'\n",
      " 'Foreign Language Study & Reference Books' 'Mathematics Books'\n",
      " 'Political Books' 'Philosophy Books' 'Sports & Outdoor Books'\n",
      " 'Language Arts & Disciplines' 'Business & Money' 'Nonfiction' 'History'\n",
      " 'Law']\n"
     ]
    }
   ],
   "source": [
    "# reviewing unique categories #\n",
    "print(df.sub_cat.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T04:21:24.930919Z",
     "start_time": "2018-07-18T04:21:24.910130Z"
    }
   },
   "outputs": [],
   "source": [
    "data = df.longDn.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T04:21:50.957999Z",
     "start_time": "2018-07-18T04:21:24.936587Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<input>:12: DeprecationWarning: invalid escape sequence \\|\n",
      "<input>:12: DeprecationWarning: invalid escape sequence \\|\n",
      "<input>:12: DeprecationWarning: invalid escape sequence \\|\n",
      "<input>:12: DeprecationWarning: invalid escape sequence \\|\n",
      "<input>:12: DeprecationWarning: invalid escape sequence \\|\n",
      "<input>:12: DeprecationWarning: invalid escape sequence \\|\n",
      "<input>:12: DeprecationWarning: invalid escape sequence \\|\n",
      "<input>:12: DeprecationWarning: invalid escape sequence \\|\n",
      "<input>:12: DeprecationWarning: invalid escape sequence \\|\n",
      "<input>:12: DeprecationWarning: invalid escape sequence \\|\n",
      "<input>:12: DeprecationWarning: invalid escape sequence \\|\n",
      "<input>:12: DeprecationWarning: invalid escape sequence \\|\n",
      "<input>:12: DeprecationWarning: invalid escape sequence \\|\n",
      "<input>:16: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:12: DeprecationWarning: invalid escape sequence \\|\n",
      "<input>:16: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:12: DeprecationWarning: invalid escape sequence \\|\n",
      "<input>:16: DeprecationWarning: invalid escape sequence \\s\n",
      "<ipython-input-14-05518dedb477>:12: DeprecationWarning: invalid escape sequence \\|\n",
      "  data = [re.sub(\"\\|\", \" \", sent) for sent in data]\n",
      "<ipython-input-14-05518dedb477>:16: DeprecationWarning: invalid escape sequence \\s\n",
      "  data = [re.sub(\"\\s+\", \" \", sent) for sent in data] #strip extra spaces\n"
     ]
    }
   ],
   "source": [
    "# converting contractions\n",
    "data = [re.sub(\"won't\",\"will not\", sent) for sent in data]\n",
    "data = [re.sub(\"can't\",\"can not\", sent) for sent in data]\n",
    "data = [re.sub(\"n't\",\"not\", sent) for sent in data]\n",
    "data = [re.sub(\"\\'ll\",\" will\", sent) for sent in data]\n",
    "data = [re.sub(\"\\'re\",\" are\", sent) for sent in data]\n",
    "data = [re.sub(\"\\'ve\",\" have\", sent) for sent in data]\n",
    "\n",
    "# removing any single quotes\n",
    "data = [re.sub(\"\\'\", \" \", sent) for sent in data] \n",
    "# removing pipes to help with saving csv as pipe-delimited\n",
    "data = [re.sub(\"\\|\", \" \", sent) for sent in data]\n",
    "# leave only letters and numbers (makes above lines redundant, but that's ok)\n",
    "data = [re.sub(\"[^a-zA-Z0-9 ]\", \" \", sent) for sent in data]\n",
    "# removing any extraneous spaces\n",
    "data = [re.sub(\"\\s+\", \" \", sent) for sent in data] #strip extra spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T04:21:50.967969Z",
     "start_time": "2018-07-18T04:21:50.961026Z"
    }
   },
   "outputs": [],
   "source": [
    "# random check to ensure clean data\n",
    "data[300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T04:23:16.671957Z",
     "start_time": "2018-07-18T04:21:50.970961Z"
    }
   },
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "data_words = list(sent_to_words(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T04:28:41.688597Z",
     "start_time": "2018-07-18T04:23:16.673763Z"
    }
   },
   "outputs": [],
   "source": [
    "# Build the bigrams and trigrams\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=50) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T04:28:41.709507Z",
     "start_time": "2018-07-18T04:28:41.690558Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T04:55:48.826376Z",
     "start_time": "2018-07-18T04:28:41.713497Z"
    }
   },
   "outputs": [],
   "source": [
    "data_words_nostops = remove_stopwords(data_words)\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "#print(data_lemmatized[:4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T04:56:21.352682Z",
     "start_time": "2018-07-18T04:55:48.832361Z"
    }
   },
   "outputs": [],
   "source": [
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-20T00:54:22.678040Z",
     "start_time": "2018-07-19T22:07:07.170609Z"
    }
   },
   "outputs": [],
   "source": [
    "final_lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=30, \n",
    "                                           random_state=100,\n",
    "                                           chunksize=50000,    # chunksize = number of docs to be used in each training chunk\n",
    "                                           passes=50,\n",
    "                                           per_word_topics=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-20T03:54:29.469286Z",
     "start_time": "2018-07-20T03:54:29.453759Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-20T03:30:15.465778Z",
     "start_time": "2018-07-20T03:30:15.453808Z"
    }
   },
   "outputs": [],
   "source": [
    "for topic in range(final_lda_model.num_topics):\n",
    "    plt.figure(figsize=(12,10))\n",
    "    #defining 1080x720 dimensions improved text clarity.\n",
    "    plt.imshow(WordCloud(background_color='white',width=1080, height=720).fit_words(dict(final_lda_model.show_topic(topic, 100)))) \n",
    "    plt.title(\"Topic Number: \" + str(topic+1))\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout(pad=0)\n",
    "    plt.savefig('shiny/Walmart_Book_Topic_Modeling/images/topic_' + str(topic+1) + '.png', transparent=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## final_lda_model.print_topic(29, topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort_topics=False prevents reordering by pyLDAvis, allowing for topic # to match gensim output, linking word cloud to LDAvis\n",
    "vis = pyLDAvis.gensim.prepare(final_lda_model, corpus, id2word, sort_topics=False) \n",
    "pyLDAvis.save_html(vis,'vis_30.html')\n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How many topics should we train? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T05:26:41.116419Z",
     "start_time": "2018-07-18T04:56:21.354673Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=20, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA multiecore models\n",
    "    coherence_values : Coherence values corresponding to the LDA multicore model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.ldamulticore.LdaMulticore(corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values\n",
    "\n",
    "\n",
    "\"\"\"    \n",
    "    Warning: This WILL take a while \n",
    "\"\"\"\n",
    "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=data_lemmatized, start=10, limit=40, step=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T05:26:41.550127Z",
     "start_time": "2018-07-18T05:26:41.138794Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show graph\n",
    "start=10; limit=40; step=3;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()\n",
    "\n",
    "# Print the coherence scores\n",
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T06:10:32.507225Z",
     "start_time": "2018-07-18T05:26:41.554084Z"
    }
   },
   "outputs": [],
   "source": [
    "############################################################\n",
    "# comparing LDA model coherence scores vs. LDA Multicore\n",
    "############################################################\n",
    "#  As expected (and unexplained) LDA Model performs better\n",
    "#  than the LDA multicore model with identical parameters \n",
    "############################################################\n",
    "\n",
    "\n",
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=20, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.ldamodel.LdaModel(corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values\n",
    "\n",
    "\"\"\"    \n",
    "    Warning: This WILL take a while \n",
    "\"\"\"\n",
    "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=data_lemmatized, start=30, limit=45, step=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T06:10:32.769936Z",
     "start_time": "2018-07-18T06:10:32.526260Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print graph\n",
    "limit=45; start=30; step=3;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()\n",
    "\n",
    "# Print coherence scores\n",
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#          LDA Multicore results:   \n",
    "big_df  \n",
    ">  Num Topics = 30  has Coherence Value of 0.4437  \n",
    ">  Num Topics = 33  has Coherence Value of 0.4106  \n",
    ">  Num Topics = 36  has Coherence Value of 0.4513  \n",
    ">  Num Topics = 39  has Coherence Value of 0.4462  \n",
    ">  Num Topics = 42  has Coherence Value of 0.4425   \n",
    "\n",
    "bigger_df:   \n",
    "> Num Topics = 30  has Coherence Value of 0.4466  \n",
    "> Num Topics = 33  has Coherence Value of 0.4341  \n",
    "> Num Topics = 36  has Coherence Value of 0.4334  \n",
    "> Num Topics = 39  has Coherence Value of 0.4356  \n",
    "> Num Topics = 42  has Coherence Value of 0.4412  \n",
    "\n",
    "#            LDA Model results:   \n",
    "big_df  \n",
    "> Num Topics = 30  has Coherence Value of 0.5116  \n",
    "> Num Topics = 33  has Coherence Value of 0.5101  \n",
    "> Num Topics = 36  has Coherence Value of 0.5146  \n",
    "> Num Topics = 39  has Coherence Value of 0.4696  \n",
    ">  Num Topics = 42  has Coherence Value of 0.4832  \n",
    " \n",
    "bigger_df:  \n",
    "> Num Topics = 30  has Coherence Value of 0.5535  \n",
    "> Num Topics = 33  has Coherence Value of 0.4843  \n",
    "> Num Topics = 36  has Coherence Value of 0.4783  \n",
    "> Num Topics = 39  has Coherence Value of 0.4902  \n",
    "> Num Topics = 42  has Coherence Value of 0.4779  \n",
    "      \n",
    "  As expected (and unexplained) LDA Model performs better   \n",
    "  than the LDA multicore model with identical parameters   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempting high score: Topics: 30, chunks: 50k, passes=20\n",
    "\n",
    "> New Best Model? Yes  \n",
    "> Runtime: 1 hour (3439 seconds)   \n",
    "> Perplexity: -8.6129  \n",
    "> Coherence Score: 0.6238   \n",
    "\n",
    "added 'new' as stopword, coherence dropped to 0.603. Decision reversed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T06:10:32.810824Z",
     "start_time": "2018-07-18T06:10:32.771960Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_model(topics=30, chunksize=50000, passes=50):\n",
    "    lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                               id2word=id2word,\n",
    "                                               num_topics=topics, \n",
    "                                               random_state=100,\n",
    "                                               chunksize=chunksize,    # chunksize = number of docs to be used in each training chunk\n",
    "                                               passes=passes,\n",
    "                                               per_word_topics=True)\n",
    "\n",
    "    # Compute Perplexity\n",
    "    print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "    # Compute Coherence Score\n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "    coherence_lda = coherence_model_lda.get_coherence()\n",
    "    print('\\nCoherence Score: ', coherence_lda)\n",
    "\n",
    "    vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "    pyLDAvis.save_html(vis,'vis_' + str(topics) + '.html')\n",
    "    vis\n",
    "    return;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T06:10:32.824786Z",
     "start_time": "2018-07-18T06:10:32.812818Z"
    }
   },
   "outputs": [],
   "source": [
    "#run_model(topics=30, chunksize=50000, passes=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempting new high score: Topics: 30, chunks: 50k, passes=50\n",
    "\n",
    "> New Best Model? Yes. Marginal improvement in Coherence Score (0.0034) by increasing from 20 to 50 passes.  \n",
    "> Runtime: unclocked.   \n",
    "> Perplexity: -8.609     \n",
    "> Coherence Score: 0.6272     \n",
    "\n",
    "added stopword 'new' and coherence decreased to 0.6078. Decision reversed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T08:15:41.481607Z",
     "start_time": "2018-07-18T06:10:32.826780Z"
    }
   },
   "outputs": [],
   "source": [
    "run_model(topics=30, chunksize=50000, passes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-15T01:25:14.115080Z",
     "start_time": "2018-07-15T01:19:12.366511Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trying same best model, separate random state (100 -> 200)\n",
    "Before:  \n",
    "> Runtime: 3hrs 25 minutes (12,209 seconds).   \n",
    "> Perplexity: -8.609     \n",
    "> Coherence Score: 0.6272    \n",
    " \n",
    "After (random state changed to 200):  \n",
    "> Runtime: 2hrs 15min (8,111 seconds)  \n",
    "> Perplexity: -8.603    \n",
    "> Coherence Score: 0.611      \n",
    "\n",
    "Results: Similar score, no improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-15T03:38:08.515765Z",
     "start_time": "2018-07-15T01:25:14.121064Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-15T03:43:12.459995Z",
     "start_time": "2018-07-15T03:38:08.520788Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-15T03:43:12.471964Z",
     "start_time": "2018-07-15T03:43:12.464982Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-15T03:43:12.494903Z",
     "start_time": "2018-07-15T03:43:12.474958Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T09:39:20.966566Z",
     "start_time": "2018-07-18T08:15:41.489477Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=data_lemmatized, start=25, limit=45, step=2)\n",
    "\n",
    "start=25; limit=45; step=2;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()\n",
    "\n",
    "# Print coherence scores\n",
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-15T10:05:16.169671Z",
     "start_time": "2018-07-15T08:03:49.399168Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T11:09:32.213066Z",
     "start_time": "2018-07-18T09:39:20.970522Z"
    }
   },
   "outputs": [],
   "source": [
    "run_model(topics=20, chunksize=40000, passes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T12:41:38.243055Z",
     "start_time": "2018-07-18T11:09:32.220029Z"
    }
   },
   "outputs": [],
   "source": [
    "run_model(topics=23, chunksize=40000, passes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T14:36:38.590765Z",
     "start_time": "2018-07-18T12:41:38.250367Z"
    }
   },
   "outputs": [],
   "source": [
    "run_model(topics=25, chunksize=50000, passes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T16:44:34.898917Z",
     "start_time": "2018-07-18T14:36:38.596813Z"
    }
   },
   "outputs": [],
   "source": [
    "run_model(topics=28, chunksize=50000, passes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T18:51:39.836984Z",
     "start_time": "2018-07-18T16:44:34.909889Z"
    }
   },
   "outputs": [],
   "source": [
    "run_model(topics=32, chunksize=50000, passes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T21:47:08.614503Z",
     "start_time": "2018-07-18T18:58:46.865048Z"
    }
   },
   "outputs": [],
   "source": [
    "run_model(topics=35, chunksize=50000, passes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T00:20:55.620551Z",
     "start_time": "2018-07-18T21:47:08.624522Z"
    }
   },
   "outputs": [],
   "source": [
    "run_model(topics=37, chunksize=40000, passes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T01:46:31.607570Z",
     "start_time": "2018-07-19T00:20:55.628546Z"
    }
   },
   "outputs": [],
   "source": [
    "run_model(topics=17, chunksize=40000, passes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T03:09:08.533709Z",
     "start_time": "2018-07-19T01:46:31.618675Z"
    }
   },
   "outputs": [],
   "source": [
    "run_model(topics=12, chunksize=40000, passes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
